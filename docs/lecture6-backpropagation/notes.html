<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.319">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CS 152: Neural Networks - Lecture 6: Deep neural networks and backpropagation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
<link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">CS 152: Neural Networks</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../calendar/calendar.html" rel="" target="">
 <span class="menu-text">Calendar</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/orgs/CS152-Neural-Networks-Fall-2023/repositories" rel="" target="">
 <span class="menu-text">Homeworks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://harveymuddcollege.instructure.com/courses/615/" rel="" target="">
 <span class="menu-text">Canvas</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/orgs/CS152-Neural-Networks-Fall-2023/" rel="" target="">
 <span class="menu-text">Github</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link active" data-scroll-target="#neural-networks">Neural networks</a>
  <ul class="collapse">
  <li><a href="#neural-networks-with-matrices" id="toc-neural-networks-with-matrices" class="nav-link" data-scroll-target="#neural-networks-with-matrices">Neural networks with matrices</a></li>
  <li><a href="#benefits-of-neural-networks" id="toc-benefits-of-neural-networks" class="nav-link" data-scroll-target="#benefits-of-neural-networks">Benefits of neural networks</a></li>
  <li><a href="#deep-neural-networks" id="toc-deep-neural-networks" class="nav-link" data-scroll-target="#deep-neural-networks">Deep Neural Networks</a></li>
  <li><a href="#optimizing-neural-networks" id="toc-optimizing-neural-networks" class="nav-link" data-scroll-target="#optimizing-neural-networks">Optimizing neural networks</a></li>
  </ul></li>
  <li><a href="#automatic-differentiation" id="toc-automatic-differentiation" class="nav-link" data-scroll-target="#automatic-differentiation">Automatic Differentiation</a>
  <ul class="collapse">
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation">Motivation</a></li>
  <li><a href="#the-chain-rule-revisited" id="toc-the-chain-rule-revisited" class="nav-link" data-scroll-target="#the-chain-rule-revisited">The chain rule revisited</a></li>
  <li><a href="#composing-many-operations" id="toc-composing-many-operations" class="nav-link" data-scroll-target="#composing-many-operations">Composing many operations</a></li>
  <li><a href="#forward-and-reverse-mode-automatic-differentiation" id="toc-forward-and-reverse-mode-automatic-differentiation" class="nav-link" data-scroll-target="#forward-and-reverse-mode-automatic-differentiation">Forward and reverse mode automatic differentiation</a></li>
  <li><a href="#automatic-differentiation-with-multiple-inputs" id="toc-automatic-differentiation-with-multiple-inputs" class="nav-link" data-scroll-target="#automatic-differentiation-with-multiple-inputs">Automatic differentiation with multiple inputs</a></li>
  <li><a href="#reusing-values" id="toc-reusing-values" class="nav-link" data-scroll-target="#reusing-values">Reusing values</a></li>
  <li><a href="#partial-and-total-derivatives" id="toc-partial-and-total-derivatives" class="nav-link" data-scroll-target="#partial-and-total-derivatives">Partial and total derivatives</a></li>
  <li><a href="#implementing-automatic-differentiation" id="toc-implementing-automatic-differentiation" class="nav-link" data-scroll-target="#implementing-automatic-differentiation">Implementing automatic differentiation</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lecture 6: Deep neural networks and backpropagation</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell">
<div class="sourceCode cell-code hidden" id="cb1" data-startfrom="1" data-source-offset="-0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>Plot <span class="op">=</span> <span class="im">import</span>(<span class="st">"https://esm.sh/@observablehq/plot"</span>) </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>d3 <span class="op">=</span> <span class="pp">require</span>(<span class="st">"d3@7"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>topojson <span class="op">=</span> <span class="pp">require</span>(<span class="st">"topojson"</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>MathJax <span class="op">=</span> <span class="pp">require</span>(<span class="st">"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.min.js"</span>)<span class="op">.</span><span class="fu">catch</span>(() <span class="kw">=&gt;</span> <span class="bu">window</span><span class="op">.</span><span class="at">MathJax</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>tf <span class="op">=</span> <span class="pp">require</span>(<span class="st">"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"</span>)<span class="op">.</span><span class="fu">catch</span>(() <span class="kw">=&gt;</span> <span class="bu">window</span><span class="op">.</span><span class="at">tf</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>THREE <span class="op">=</span> {</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> THREE <span class="op">=</span> <span class="bu">window</span><span class="op">.</span><span class="at">THREE</span> <span class="op">=</span> <span class="cf">await</span> <span class="pp">require</span>(<span class="st">"three@0.130.0/build/three.min.js"</span>)<span class="op">;</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">await</span> <span class="pp">require</span>(<span class="st">"three@0.130.0/examples/js/controls/OrbitControls.js"</span>)<span class="op">.</span><span class="fu">catch</span>(() <span class="kw">=&gt;</span> {})<span class="op">;</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">await</span> <span class="pp">require</span>(<span class="st">"three@0.130.0/examples/js/loaders/SVGLoader.js"</span>)<span class="op">.</span><span class="fu">catch</span>(() <span class="kw">=&gt;</span> {})<span class="op">;</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> THREE<span class="op">;</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">sample</span>(f<span class="op">,</span> start<span class="op">,</span> end<span class="op">,</span> nsamples<span class="op">=</span><span class="dv">100</span>) {</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> arr <span class="op">=</span> [<span class="op">...</span><span class="bu">Array</span>(nsamples)<span class="op">.</span><span class="fu">keys</span>()]</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> dist <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  <span class="kw">function</span> <span class="fu">arrmap</span>(ind) {</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> x <span class="op">=</span> (ind <span class="op">*</span> dist) <span class="op">/</span> nsamples <span class="op">+</span> start<span class="op">;</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [x<span class="op">,</span> <span class="fu">f</span>(x)]<span class="op">;</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> arr<span class="op">.</span><span class="fu">map</span>(arrmap)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">sigmoid</span>(x){</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">exp</span>(<span class="op">-</span>x))<span class="op">;</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">sum</span>(x) {</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> s <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (<span class="kw">let</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> x<span class="op">.</span><span class="at">length</span><span class="op">;</span> i<span class="op">++</span> ) {</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    s <span class="op">+=</span> x[i]<span class="op">;</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> s<span class="op">;</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">mean</span>(x) {</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> s <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (<span class="kw">let</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> x<span class="op">.</span><span class="at">length</span><span class="op">;</span> i<span class="op">++</span> ) {</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    s <span class="op">+=</span> x[i]<span class="op">;</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> s <span class="op">/</span> x<span class="op">.</span><span class="at">length</span><span class="op">;</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">cross_ent</span>(x<span class="op">,</span> y) {</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> y <span class="op">?</span> <span class="op">-</span><span class="bu">Math</span><span class="op">.</span><span class="fu">log</span>(<span class="fu">sigmoid</span>(x)) <span class="op">:</span> <span class="op">-</span><span class="bu">Math</span><span class="op">.</span><span class="fu">log</span>(<span class="fu">sigmoid</span>(<span class="op">-</span>x))<span class="op">;</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">se</span>(x<span class="op">,</span> y) {</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (x <span class="op">-</span> y) <span class="op">*</span> (x <span class="op">-</span> y)<span class="op">;</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">shuffle</span>(array) {</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> currentIndex <span class="op">=</span> array<span class="op">.</span><span class="at">length</span><span class="op">,</span>  randomIndex<span class="op">;</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>  <span class="co">// While there remain elements to shuffle.</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>  <span class="cf">while</span> (currentIndex <span class="op">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Pick a remaining element.</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>    randomIndex <span class="op">=</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">floor</span>(<span class="bu">Math</span><span class="op">.</span><span class="fu">random</span>() <span class="op">*</span> currentIndex)<span class="op">;</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>    currentIndex<span class="op">--;</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    <span class="co">// And swap it with the current element.</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    [array[currentIndex]<span class="op">,</span> array[randomIndex]] <span class="op">=</span> [</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>      array[randomIndex]<span class="op">,</span> array[currentIndex]]<span class="op">;</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> array<span class="op">;</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">acc</span>(x<span class="op">,</span> y) {</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="bu">Number</span>(y <span class="op">==</span> (x  <span class="op">&gt;</span> <span class="dv">0</span>))<span class="op">;</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">grid_func</span>(f<span class="op">,</span> width<span class="op">,</span> height<span class="op">,</span> x1<span class="op">,</span> y1<span class="op">,</span> x2<span class="op">,</span> y2) {</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> values <span class="op">=</span> <span class="kw">new</span> <span class="bu">Array</span>(width <span class="op">*</span> height)<span class="op">;</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> xstride <span class="op">=</span> (x2 <span class="op">-</span> x1) <span class="op">/</span> width<span class="op">;</span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> ystride <span class="op">=</span> (y2 <span class="op">-</span> y1) <span class="op">/</span> height<span class="op">;</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> y <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> x <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> ind <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (<span class="kw">let</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> height<span class="op">;</span> i<span class="op">++</span> ) {</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (<span class="kw">let</span> j <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> j <span class="op">&lt;</span> width<span class="op">;</span> j<span class="op">++,</span> ind<span class="op">++</span>) {</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>      x <span class="op">=</span> x1 <span class="op">+</span> j <span class="op">*</span> xstride<span class="op">;</span></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>      y <span class="op">=</span> y1 <span class="op">+</span> i <span class="op">*</span> ystride<span class="op">;</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>      values[ind] <span class="op">=</span> <span class="fu">f</span>(x<span class="op">,</span> y)<span class="op">;</span></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> {<span class="dt">width</span><span class="op">:</span> width<span class="op">,</span> <span class="dt">height</span><span class="op">:</span> height<span class="op">,</span> <span class="dt">x1</span><span class="op">:</span> x1<span class="op">,</span> <span class="dt">y1</span><span class="op">:</span> y1<span class="op">,</span> <span class="dt">x2</span><span class="op">:</span> x2<span class="op">,</span> <span class="dt">y2</span><span class="op">:</span> y2<span class="op">,</span> <span class="dt">values</span><span class="op">:</span> values}<span class="op">;</span></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">get_accessors</span>(keys<span class="op">,</span> byindex<span class="op">=</span><span class="kw">false</span>) {</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> isString <span class="op">=</span> value <span class="kw">=&gt;</span> <span class="kw">typeof</span> value <span class="op">===</span> <span class="st">'string'</span><span class="op">;</span></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> index <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> indexmap <span class="op">=</span> {}<span class="op">;</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> accessors <span class="op">=</span> []<span class="op">;</span></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (<span class="kw">let</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> keys<span class="op">.</span><span class="at">length</span><span class="op">;</span> i<span class="op">++</span>){</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> k <span class="op">=</span> keys[i]<span class="op">;</span></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="bu">Array</span><span class="op">.</span><span class="fu">isArray</span>(k)) {</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>      <span class="kw">let</span> access <span class="op">=</span> <span class="fu">isString</span>(k[<span class="dv">0</span>]) <span class="op">?</span> (x <span class="kw">=&gt;</span> x[k[<span class="dv">0</span>]]) <span class="op">:</span> k[<span class="dv">0</span>]<span class="op">;</span></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (byindex) {</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (<span class="fu">isString</span>(k[<span class="dv">0</span>]) <span class="op">&amp;&amp;</span> <span class="op">!</span>(k[<span class="dv">0</span>] <span class="kw">in</span> indexmap)) {</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>          indexmap[k[<span class="dv">0</span>]] <span class="op">=</span> index<span class="op">;</span></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>          index<span class="op">++;</span></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> accessindex <span class="op">=</span> indexmap[k[<span class="dv">0</span>]]<span class="op">;</span></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>        access <span class="op">=</span> x <span class="kw">=&gt;</span> x[accessindex]<span class="op">;</span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> <span class="bu">process</span> <span class="op">=</span> k[<span class="dv">1</span>]<span class="op">;</span></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> final_access <span class="op">=</span> x <span class="kw">=&gt;</span> <span class="bu">process</span>(<span class="fu">access</span>(x))<span class="op">;</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>        accessors<span class="op">.</span><span class="fu">push</span>(final_access)<span class="op">;</span></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span> {</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> <span class="bu">process</span> <span class="op">=</span> k[<span class="dv">1</span>]<span class="op">;</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> final_access <span class="op">=</span> x <span class="kw">=&gt;</span> <span class="bu">process</span>(<span class="fu">access</span>(x))<span class="op">;</span></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>        accessors<span class="op">.</span><span class="fu">push</span>(final_access)<span class="op">;</span></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> {</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>      <span class="kw">let</span> access <span class="op">=</span> <span class="fu">isString</span>(k) <span class="op">?</span> (x <span class="kw">=&gt;</span> x[k]) <span class="op">:</span> k<span class="op">;</span></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (byindex) { </span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (<span class="fu">isString</span>(k) <span class="op">&amp;&amp;</span> <span class="op">!</span>(k <span class="kw">in</span> indexmap)) {</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>          indexmap[k] <span class="op">=</span> index<span class="op">;</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>          index<span class="op">++;</span></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> accessindex <span class="op">=</span> indexmap[k]<span class="op">;</span></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>        access <span class="op">=</span> x <span class="kw">=&gt;</span> x[accessindex]<span class="op">;</span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>      accessors<span class="op">.</span><span class="fu">push</span>(access)<span class="op">;</span> </span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> accessors<span class="op">;</span></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">predict</span>(obs<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">=</span>[<span class="st">"0"</span><span class="op">,</span> <span class="st">"1"</span><span class="op">,</span> <span class="st">"2"</span><span class="op">,</span> <span class="st">"3"</span>]<span class="op">,</span> byindex<span class="op">=</span><span class="kw">false</span>) {</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> isString <span class="op">=</span> value <span class="kw">=&gt;</span> <span class="kw">typeof</span> value <span class="op">===</span> <span class="st">'string'</span><span class="op">;</span></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> accessors <span class="op">=</span> <span class="fu">get_accessors</span>(keys<span class="op">,</span> byindex)<span class="op">;</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> output <span class="op">=</span> weights[<span class="dv">0</span>]<span class="op">;</span></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> wi <span class="op">=</span> <span class="dv">1</span><span class="op">;</span></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (<span class="kw">let</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> (i <span class="op">&lt;</span> keys<span class="op">.</span><span class="at">length</span>) <span class="op">&amp;&amp;</span> (wi <span class="op">&lt;</span> weights<span class="op">.</span><span class="at">length</span>)<span class="op">;</span> i<span class="op">++,</span> wi<span class="op">++</span>){</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>    output <span class="op">+=</span> weights[wi] <span class="op">*</span> accessors[i](obs)<span class="op">;</span></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> output<span class="op">;</span></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">mean_loss</span>(f<span class="op">,</span> data<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">,</span> label<span class="op">,</span> l2<span class="op">=</span><span class="dv">0</span>) {</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> reg <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (l2 <span class="op">&gt;</span> <span class="dv">0</span>){</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (<span class="kw">let</span> i <span class="op">=</span> <span class="dv">1</span><span class="op">;</span> i <span class="op">&lt;</span> weights<span class="op">.</span><span class="at">length</span><span class="op">;</span> i<span class="op">++</span>) {</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>      reg <span class="op">+=</span> weights[i] <span class="op">*</span> weights[i]<span class="op">;</span></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> isString <span class="op">=</span> value <span class="kw">=&gt;</span> <span class="kw">typeof</span> value <span class="op">===</span> <span class="st">'string'</span><span class="op">;</span></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> get_label <span class="op">=</span> <span class="fu">isString</span>(label) <span class="op">?</span> (x <span class="kw">=&gt;</span> x[label]) <span class="op">:</span> label<span class="op">;</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="fu">mean</span>(data<span class="op">.</span><span class="fu">map</span>(x <span class="kw">=&gt;</span> <span class="fu">f</span>(<span class="fu">predict</span>(x<span class="op">,</span> weights<span class="op">,</span> keys)<span class="op">,</span> <span class="fu">get_label</span>(x)))) <span class="op">+</span> l2 <span class="op">*</span> reg<span class="op">;</span></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">get_domains</span>(data<span class="op">,</span> accessors<span class="op">,</span> margin<span class="op">=</span><span class="fl">0.1</span>) {</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> domains <span class="op">=</span> []<span class="op">;</span></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (<span class="kw">let</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> accessors<span class="op">.</span><span class="at">length</span><span class="op">;</span> i<span class="op">++</span>){</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> xdomain <span class="op">=</span> d3<span class="op">.</span><span class="fu">extent</span>(data<span class="op">,</span> accessors[i])<span class="op">;</span></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> xdsize <span class="op">=</span> (xdomain[<span class="dv">1</span>] <span class="op">-</span> xdomain[<span class="dv">0</span>])<span class="op">;</span></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> xmin <span class="op">=</span> xdomain[<span class="dv">0</span>] <span class="op">-</span> xdsize <span class="op">*</span> margin<span class="op">;</span></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> xmax <span class="op">=</span> xdomain[<span class="dv">1</span>] <span class="op">+</span> xdsize <span class="op">*</span> margin<span class="op">;</span></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>    domains<span class="op">.</span><span class="fu">push</span>([xmin<span class="op">,</span> xmax])<span class="op">;</span></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> domains<span class="op">;</span></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">logisticPlot2d</span>(data<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">,</span> label<span class="op">,</span> interval<span class="op">=</span><span class="fl">0.05</span>) {</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> accuracy <span class="op">=</span> <span class="fu">mean_loss</span>(acc<span class="op">,</span> data<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">,</span> label)<span class="op">;</span></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> isString <span class="op">=</span> value <span class="kw">=&gt;</span> <span class="kw">typeof</span> value <span class="op">===</span> <span class="st">'string'</span><span class="op">;</span></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> accessors <span class="op">=</span> <span class="fu">get_accessors</span>(keys)<span class="op">;</span></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> index_accessors <span class="op">=</span> <span class="fu">get_accessors</span>(keys<span class="op">,</span> <span class="kw">true</span>)<span class="op">;</span></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> domains <span class="op">=</span> <span class="fu">get_domains</span>(data<span class="op">,</span> accessors)<span class="op">;</span></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> get_label <span class="op">=</span> <span class="fu">isString</span>(label) <span class="op">?</span> (x <span class="kw">=&gt;</span> x[label]) <span class="op">:</span> label<span class="op">;</span></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> Plot<span class="op">.</span><span class="fu">plot</span>({</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>    <span class="dt">x</span><span class="op">:</span> {<span class="dt">tickSpacing</span><span class="op">:</span> <span class="dv">80</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"x"</span>}<span class="op">,</span></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>    <span class="dt">y</span><span class="op">:</span> {<span class="dt">tickSpacing</span><span class="op">:</span> <span class="dv">80</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"y"</span>}<span class="op">,</span></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>    <span class="dt">title</span><span class="op">:</span> <span class="st">"Accuracy: "</span> <span class="op">+</span> accuracy<span class="op">.</span><span class="fu">toFixed</span>(<span class="dv">3</span>)<span class="op">,</span></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>    <span class="dt">color</span><span class="op">:</span> {<span class="dt">type</span><span class="op">:</span> <span class="st">"linear"</span><span class="op">,</span> <span class="dt">legend</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="dt">scheme</span><span class="op">:</span> <span class="st">"BuRd"</span><span class="op">,</span> <span class="dt">domain</span><span class="op">:</span> [<span class="op">-</span><span class="fl">0.5</span><span class="op">,</span> <span class="fl">1.5</span>]}<span class="op">,</span></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>    <span class="dt">marks</span><span class="op">:</span> [</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">contour</span>({</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>        <span class="dt">fill</span><span class="op">:</span> (x<span class="op">,</span> y) <span class="kw">=&gt;</span> <span class="fu">sigmoid</span>(<span class="fu">predict</span>([x<span class="op">,</span> y]<span class="op">,</span> weights<span class="op">,</span> index_accessors))<span class="op">,</span></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>        <span class="dt">x1</span><span class="op">:</span> domains[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">,</span> <span class="dt">y1</span><span class="op">:</span> domains[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">,</span> <span class="dt">x2</span><span class="op">:</span> domains[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">,</span> <span class="dt">y2</span><span class="op">:</span> domains[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">,</span> <span class="dt">interval</span><span class="op">:</span> interval<span class="op">,</span></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>      })<span class="op">,</span></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">dot</span>(data<span class="op">,</span> {<span class="dt">x</span><span class="op">:</span> accessors[<span class="dv">0</span>]<span class="op">,</span> <span class="dt">y</span><span class="op">:</span> accessors[<span class="dv">1</span>]<span class="op">,</span> <span class="dt">stroke</span><span class="op">:</span> x<span class="kw">=&gt;</span> (<span class="fu">get_label</span>(x) <span class="op">?</span> <span class="fl">1.35</span> <span class="op">:</span> <span class="op">-</span><span class="fl">0.35</span>)})</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>  })<span class="op">;</span></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">logisticLossPlot2d</span>(data<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">,</span> label) {</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> loss <span class="op">=</span> <span class="fu">mean_loss</span>(cross_ent<span class="op">,</span> data<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">,</span> label)<span class="op">;</span></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> isString <span class="op">=</span> value <span class="kw">=&gt;</span> <span class="kw">typeof</span> value <span class="op">===</span> <span class="st">'string'</span><span class="op">;</span></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> accessors <span class="op">=</span> <span class="fu">get_accessors</span>(keys)<span class="op">;</span></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> index_accessors <span class="op">=</span> <span class="fu">get_accessors</span>(keys<span class="op">,</span> <span class="kw">true</span>)<span class="op">;</span></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> domains <span class="op">=</span> <span class="fu">get_domains</span>(data<span class="op">,</span> accessors)<span class="op">;</span></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> get_label <span class="op">=</span> <span class="fu">isString</span>(label) <span class="op">?</span> (x <span class="kw">=&gt;</span> x[label]) <span class="op">:</span> label<span class="op">;</span></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> Plot<span class="op">.</span><span class="fu">plot</span>({</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>    <span class="dt">x</span><span class="op">:</span> {<span class="dt">tickSpacing</span><span class="op">:</span> <span class="dv">80</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"x"</span>}<span class="op">,</span></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>    <span class="dt">y</span><span class="op">:</span> {<span class="dt">tickSpacing</span><span class="op">:</span> <span class="dv">80</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"y"</span>}<span class="op">,</span></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>    <span class="dt">title</span><span class="op">:</span> <span class="st">"Loss: "</span> <span class="op">+</span> loss<span class="op">.</span><span class="fu">toFixed</span>(<span class="dv">3</span>)<span class="op">,</span></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>    <span class="dt">color</span><span class="op">:</span> {<span class="dt">type</span><span class="op">:</span> <span class="st">"linear"</span><span class="op">,</span> <span class="dt">legend</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="dt">scheme</span><span class="op">:</span> <span class="st">"BuRd"</span><span class="op">,</span> <span class="dt">domain</span><span class="op">:</span> [<span class="dv">0</span><span class="op">,</span> <span class="dv">5</span>]}<span class="op">,</span></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>    <span class="dt">marks</span><span class="op">:</span> [</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">contour</span>({</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>        <span class="dt">value</span><span class="op">:</span> (x<span class="op">,</span> y) <span class="kw">=&gt;</span> <span class="fu">predict</span>([x<span class="op">,</span> y]<span class="op">,</span> weights<span class="op">,</span> index_accessors)<span class="op">,</span></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>        <span class="dt">fillOpacity</span><span class="op">:</span> <span class="fl">0.2</span><span class="op">,</span></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>        <span class="dt">stroke</span><span class="op">:</span> <span class="st">"black"</span><span class="op">,</span> <span class="dt">x1</span><span class="op">:</span> domains[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">,</span> <span class="dt">y1</span><span class="op">:</span> domains[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">,</span> <span class="dt">x2</span><span class="op">:</span> domains[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">,</span> <span class="dt">y2</span><span class="op">:</span> domains[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">,</span></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>        <span class="dt">thresholds</span><span class="op">:</span> [<span class="op">-</span><span class="fl">1e6</span><span class="op">,</span>  <span class="dv">0</span><span class="op">,</span> <span class="fl">0.00001</span>]</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>      })<span class="op">,</span></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">dot</span>(data<span class="op">,</span> {<span class="dt">x</span><span class="op">:</span> accessors[<span class="dv">0</span>]<span class="op">,</span> <span class="dt">y</span><span class="op">:</span> accessors[<span class="dv">1</span>]<span class="op">,</span> <span class="dt">stroke</span><span class="op">:</span> x<span class="kw">=&gt;</span> <span class="fu">cross_ent</span>(<span class="fu">predict</span>(x<span class="op">,</span> weights<span class="op">,</span> keys)<span class="op">,</span> <span class="fu">get_label</span>(x))<span class="op">,</span> </span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>                      <span class="dt">strokeOpacity</span><span class="op">:</span> <span class="fl">0.5</span> })</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>  })<span class="op">;</span></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">lossPlot2d</span>(f<span class="op">,</span> data<span class="op">,</span> keys<span class="op">,</span> label<span class="op">,</span> l2<span class="op">=</span><span class="dv">0</span><span class="op">,</span> res<span class="op">=</span><span class="dv">100</span><span class="op">,</span> x1<span class="op">=-</span><span class="dv">40</span><span class="op">,</span> y1<span class="op">=-</span><span class="fl">0.015</span><span class="op">,</span> x2<span class="op">=</span><span class="dv">40</span><span class="op">,</span>  y2<span class="op">=</span><span class="fl">0.015</span><span class="op">,</span> vmax<span class="op">=</span><span class="dv">50</span><span class="op">,</span> nlines<span class="op">=</span><span class="dv">25</span><span class="op">,</span> ctype<span class="op">=</span><span class="st">"sqrt"</span><span class="op">,</span> scale<span class="op">=</span>(x <span class="kw">=&gt;</span> x)) {</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> grid <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>  <span class="kw">function</span> <span class="fu">lossFunc</span>(w<span class="op">,</span> b) {</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fu">scale</span>(<span class="fu">mean_loss</span>(f<span class="op">,</span> data<span class="op">,</span> [w<span class="op">,</span> b]<span class="op">,</span> keys<span class="op">,</span> label<span class="op">,</span> l2))<span class="op">;</span></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>  grid <span class="op">=</span> <span class="fu">grid_func</span>(lossFunc<span class="op">,</span></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>                 res<span class="op">,</span> res<span class="op">,</span> x1<span class="op">,</span> y1<span class="op">,</span> x2<span class="op">,</span> y2</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>                )<span class="op">;</span></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>  <span class="kw">function</span> <span class="fu">plot2d</span>(weights) {</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> w <span class="op">=</span> weights<span class="op">;</span></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="op">!</span>(<span class="bu">Array</span><span class="op">.</span><span class="fu">isArray</span>(w[<span class="dv">0</span>]))){</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>      w <span class="op">=</span> [w]<span class="op">;</span></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>    <span class="kw">var</span> arrows <span class="op">=</span> w<span class="op">.</span><span class="fu">slice</span>(<span class="dv">0</span><span class="op">,</span> w<span class="op">.</span><span class="at">length</span> <span class="op">-</span> <span class="dv">1</span>)<span class="op">.</span><span class="fu">map</span>(<span class="kw">function</span>(e<span class="op">,</span> i) {</span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> e<span class="op">.</span><span class="fu">concat</span>(w[i<span class="op">+</span><span class="dv">1</span>])<span class="op">;</span></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>    })<span class="op">;</span></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> interval<span class="op">=</span> vmax <span class="op">/</span> nlines<span class="op">;</span> </span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> thresholds <span class="op">=</span> []<span class="op">;</span></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (<span class="kw">let</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> nlines<span class="op">;</span> i<span class="op">++</span>) {</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>      thresholds<span class="op">.</span><span class="fu">push</span>(i <span class="op">*</span> interval)<span class="op">;</span></span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> loss <span class="op">=</span> <span class="fu">mean_loss</span>(f<span class="op">,</span> data<span class="op">,</span> w[w<span class="op">.</span><span class="at">length</span> <span class="op">-</span> <span class="dv">1</span>]<span class="op">,</span> keys<span class="op">,</span> label<span class="op">,</span> l2)</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Plot<span class="op">.</span><span class="fu">plot</span>({</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>      <span class="dt">title</span><span class="op">:</span> <span class="st">"Loss: "</span> <span class="op">+</span> loss<span class="op">.</span><span class="fu">toFixed</span>(<span class="dv">3</span>)<span class="op">,</span></span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>      <span class="dt">color</span><span class="op">:</span> {<span class="dt">type</span><span class="op">:</span> <span class="st">"linear"</span><span class="op">,</span> <span class="dt">legend</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"Loss"</span><span class="op">,</span> <span class="dt">scheme</span><span class="op">:</span> <span class="st">"BuRd"</span><span class="op">,</span> <span class="dt">domain</span><span class="op">:</span> [<span class="dv">0</span><span class="op">,</span> vmax]<span class="op">,</span> <span class="dt">type</span><span class="op">:</span> ctype}<span class="op">,</span></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>      <span class="dt">marks</span><span class="op">:</span> [</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a>        Plot<span class="op">.</span><span class="fu">contour</span>(grid<span class="op">.</span><span class="at">values</span><span class="op">,</span> {<span class="dt">width</span><span class="op">:</span> grid<span class="op">.</span><span class="at">width</span><span class="op">,</span> <span class="dt">height</span><span class="op">:</span> grid<span class="op">.</span><span class="at">height</span><span class="op">,</span> <span class="dt">x1</span><span class="op">:</span> grid<span class="op">.</span><span class="at">x1</span><span class="op">,</span> <span class="dt">x2</span><span class="op">:</span>grid<span class="op">.</span><span class="at">x2</span><span class="op">,</span> <span class="dt">y1</span><span class="op">:</span> grid<span class="op">.</span><span class="at">y1</span><span class="op">,</span> <span class="dt">y2</span><span class="op">:</span> grid<span class="op">.</span><span class="at">y2</span><span class="op">,</span></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>          <span class="dt">stroke</span><span class="op">:</span> Plot<span class="op">.</span><span class="at">identity</span><span class="op">,</span> <span class="dt">thresholds</span><span class="op">:</span> thresholds})<span class="op">,</span></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>        Plot<span class="op">.</span><span class="fu">dot</span>(w)<span class="op">,</span></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>        Plot<span class="op">.</span><span class="fu">arrow</span>(arrows<span class="op">,</span> {<span class="dt">x1</span><span class="op">:</span> <span class="st">"0"</span><span class="op">,</span> <span class="dt">y1</span><span class="op">:</span> <span class="st">"1"</span><span class="op">,</span> <span class="dt">x2</span><span class="op">:</span> <span class="st">"2"</span><span class="op">,</span> <span class="dt">y2</span><span class="op">:</span> <span class="st">"3"</span><span class="op">,</span> <span class="dt">stroke</span><span class="op">:</span> <span class="st">"black"</span>})</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>      ]</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> plot2d<span class="op">;</span></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">regressionPlot</span>(data<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">,</span> label<span class="op">,</span> l2<span class="op">,</span> f<span class="op">=</span>se<span class="op">,</span> stroke<span class="op">=</span><span class="st">""</span>) {</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> loss <span class="op">=</span> <span class="fu">mean_loss</span>(f<span class="op">,</span> data<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">,</span> label<span class="op">,</span> l2)<span class="op">;</span></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> isString <span class="op">=</span> value <span class="kw">=&gt;</span> <span class="kw">typeof</span> value <span class="op">===</span> <span class="st">'string'</span><span class="op">;</span></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> accessors <span class="op">=</span> <span class="fu">get_accessors</span>(keys)<span class="op">;</span></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> index_accessors <span class="op">=</span> <span class="fu">get_accessors</span>(keys<span class="op">,</span> <span class="kw">true</span>)<span class="op">;</span></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> domains <span class="op">=</span> <span class="fu">get_domains</span>(data<span class="op">,</span> <span class="fu">get_accessors</span>([label]<span class="op">.</span><span class="fu">concat</span>(keys)))<span class="op">;</span></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> get_label <span class="op">=</span> <span class="fu">isString</span>(label) <span class="op">?</span> (x <span class="kw">=&gt;</span> x[label]) <span class="op">:</span> label<span class="op">;</span></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> stroke_shade <span class="op">=</span> stroke<span class="op">;</span></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (stroke <span class="op">==</span> <span class="st">""</span>) {</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>    stroke_shade <span class="op">=</span> (x <span class="kw">=&gt;</span> <span class="fu">f</span>(<span class="fu">predict</span>(x<span class="op">,</span> weights<span class="op">,</span> keys)<span class="op">,</span> <span class="fu">get_label</span>(x)))</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> Plot<span class="op">.</span><span class="fu">plot</span>({</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>    <span class="dt">y</span><span class="op">:</span> {<span class="dt">domain</span><span class="op">:</span> domains[<span class="dv">0</span>]}<span class="op">,</span></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>    <span class="dt">title</span><span class="op">:</span> <span class="st">"Loss: "</span> <span class="op">+</span> loss<span class="op">.</span><span class="fu">toFixed</span>(<span class="dv">3</span>)<span class="op">,</span></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a>    <span class="dt">color</span><span class="op">:</span> {<span class="dt">type</span><span class="op">:</span> <span class="st">"linear"</span><span class="op">,</span> <span class="dt">legend</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"Loss"</span><span class="op">,</span> <span class="dt">scheme</span><span class="op">:</span> <span class="st">"BuRd"</span><span class="op">,</span> <span class="dt">domain</span><span class="op">:</span> [<span class="dv">0</span><span class="op">,</span> <span class="dv">100</span>]}<span class="op">,</span></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a>    <span class="dt">marks</span><span class="op">:</span> [</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">line</span>(<span class="fu">sample</span>((x) <span class="kw">=&gt;</span> <span class="fu">predict</span>([x]<span class="op">,</span> weights<span class="op">,</span> index_accessors)<span class="op">,</span> domains[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">,</span> domains[<span class="dv">1</span>][<span class="dv">1</span>])<span class="op">,</span> {<span class="dt">stroke</span><span class="op">:</span> <span class="st">'black'</span>})<span class="op">,</span></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">dot</span>(data<span class="op">,</span> {<span class="dt">x</span><span class="op">:</span> accessors[<span class="dv">0</span>]<span class="op">,</span> <span class="dt">y</span><span class="op">:</span> get_label<span class="op">,</span> <span class="dt">stroke</span><span class="op">:</span> stroke_shade })</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">errorPlot</span>(data<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">,</span> label<span class="op">,</span> f<span class="op">,</span> options<span class="op">=</span>{}) {</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> isString <span class="op">=</span> value <span class="kw">=&gt;</span> <span class="kw">typeof</span> value <span class="op">===</span> <span class="st">'string'</span><span class="op">;</span></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> get_label <span class="op">=</span> <span class="fu">isString</span>(label) <span class="op">?</span> (x <span class="kw">=&gt;</span> x[label]) <span class="op">:</span> label<span class="op">;</span></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> errors <span class="op">=</span> data<span class="op">.</span><span class="fu">map</span>(x <span class="kw">=&gt;</span> [<span class="fu">predict</span>(x<span class="op">,</span> weights<span class="op">,</span> keys) <span class="op">-</span> <span class="fu">get_label</span>(x)<span class="op">,</span> <span class="fu">f</span>(<span class="fu">predict</span>(x<span class="op">,</span> weights<span class="op">,</span> keys)<span class="op">,</span> <span class="fu">get_label</span>(x))])<span class="op">;</span></span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> sigma <span class="op">=</span> (options[<span class="st">'sigma'</span>] <span class="op">||</span> <span class="dv">1</span>)<span class="op">;</span></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> plots <span class="op">=</span> []<span class="op">;</span></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> xdomain <span class="op">=</span> (options[<span class="st">'xdomain'</span>] <span class="op">||</span> [<span class="op">-</span><span class="dv">30</span><span class="op">,</span> <span class="dv">30</span>])<span class="op">;</span></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> ydomain <span class="op">=</span> (options[<span class="st">'ydomain'</span>] <span class="op">||</span> [<span class="dv">0</span><span class="op">,</span> <span class="fl">0.1</span>])<span class="op">;</span></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (options[<span class="st">'plotnormal'</span>]){</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> pdf <span class="op">=</span> x <span class="kw">=&gt;</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">exp</span>(<span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> x <span class="op">*</span> x <span class="op">/</span> sigma) <span class="op">*</span> ydomain[<span class="dv">1</span>]<span class="op">;</span></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> normal <span class="op">=</span> Plot<span class="op">.</span><span class="fu">line</span>(<span class="fu">sample</span>(pdf<span class="op">,</span> xdomain[<span class="dv">0</span>]<span class="op">,</span> xdomain[<span class="dv">1</span>])<span class="op">,</span> {<span class="dt">stroke</span><span class="op">:</span> <span class="st">'crimson'</span>})<span class="op">;</span>    </span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>    plots<span class="op">.</span><span class="fu">push</span>(normal)<span class="op">;</span></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (options[<span class="st">'plotlaplace'</span>]){</span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> pdf <span class="op">=</span> x <span class="kw">=&gt;</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">exp</span>(<span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> <span class="bu">Math</span><span class="op">.</span><span class="fu">abs</span>(x) <span class="op">/</span> sigma) <span class="op">*</span> ydomain[<span class="dv">1</span>]<span class="op">;</span></span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> normal <span class="op">=</span> Plot<span class="op">.</span><span class="fu">line</span>(<span class="fu">sample</span>(pdf<span class="op">,</span> xdomain[<span class="dv">0</span>]<span class="op">,</span> xdomain[<span class="dv">1</span>])<span class="op">,</span> {<span class="dt">stroke</span><span class="op">:</span> <span class="st">'green'</span>})<span class="op">;</span>    </span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a>    plots<span class="op">.</span><span class="fu">push</span>(normal)<span class="op">;</span></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> Plot<span class="op">.</span><span class="fu">plot</span>({</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a>    <span class="dt">y</span><span class="op">:</span> {<span class="dt">grid</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="dt">domain</span><span class="op">:</span> ydomain}<span class="op">,</span></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>    <span class="dt">x</span><span class="op">:</span> {<span class="dt">domain</span><span class="op">:</span> xdomain}<span class="op">,</span></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>    <span class="dt">color</span><span class="op">:</span> {<span class="dt">type</span><span class="op">:</span> <span class="st">"linear"</span><span class="op">,</span> <span class="dt">legend</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"Loss"</span><span class="op">,</span> <span class="dt">scheme</span><span class="op">:</span> <span class="st">"BuRd"</span><span class="op">,</span> <span class="dt">domain</span><span class="op">:</span> [<span class="dv">0</span><span class="op">,</span> <span class="dv">100</span>]}<span class="op">,</span></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>    <span class="dt">marks</span><span class="op">:</span> [</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a>      <span class="co">//Plot.rectY(errors, Plot.binX({y: "count", fill: x =&gt; mean(x.map(v =&gt; v[1]))}, {x: "0"})),</span></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">rectY</span>(errors<span class="op">,</span> Plot<span class="op">.</span><span class="fu">binX</span>({<span class="dt">y</span><span class="op">:</span> <span class="st">"proportion"</span>}<span class="op">,</span> {<span class="dt">x</span><span class="op">:</span> <span class="st">"0"</span><span class="op">,</span> <span class="dt">fill</span><span class="op">:</span> <span class="st">'steelblue'</span><span class="op">,</span> <span class="dt">interval</span><span class="op">:</span> <span class="dv">1</span>}))<span class="op">,</span></span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">ruleY</span>([<span class="dv">0</span>])</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a>    ]<span class="op">.</span><span class="fu">concat</span>(plots)</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">nnPlot</span>(data<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">,</span> label<span class="op">,</span> l2<span class="op">,</span> f<span class="op">=</span>se<span class="op">,</span> stroke<span class="op">=</span><span class="st">""</span><span class="op">,</span> options<span class="op">=</span>[]) {</span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> loss <span class="op">=</span> <span class="fu">mean_loss</span>(f<span class="op">,</span> data<span class="op">,</span> weights<span class="op">,</span> keys<span class="op">,</span> label<span class="op">,</span> l2)<span class="op">;</span></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> isString <span class="op">=</span> value <span class="kw">=&gt;</span> <span class="kw">typeof</span> value <span class="op">===</span> <span class="st">'string'</span><span class="op">;</span></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> accessors <span class="op">=</span> <span class="fu">get_accessors</span>(keys)<span class="op">;</span></span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> index_accessors <span class="op">=</span> <span class="fu">get_accessors</span>(keys<span class="op">,</span> <span class="kw">true</span>)<span class="op">;</span></span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> domains <span class="op">=</span> <span class="fu">get_domains</span>(data<span class="op">,</span> <span class="fu">get_accessors</span>([label]<span class="op">.</span><span class="fu">concat</span>(keys)))<span class="op">;</span></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> get_label <span class="op">=</span> <span class="fu">isString</span>(label) <span class="op">?</span> (x <span class="kw">=&gt;</span> x[label]) <span class="op">:</span> label<span class="op">;</span></span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> stroke_shade <span class="op">=</span> stroke<span class="op">;</span></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (stroke <span class="op">==</span> <span class="st">""</span>) {</span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a>    stroke_shade <span class="op">=</span> (x <span class="kw">=&gt;</span> <span class="fu">f</span>(<span class="fu">predict</span>(x<span class="op">,</span> weights<span class="op">,</span> keys)<span class="op">,</span> <span class="fu">get_label</span>(x)))</span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> a <span class="op">=</span> []</span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (options<span class="op">.</span><span class="fu">indexOf</span>(<span class="st">"Show feature transforms"</span>) <span class="op">&gt;=</span> <span class="dv">0</span>){</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> [Plot<span class="op">.</span><span class="fu">line</span>(<span class="fu">sample</span>((x) <span class="kw">=&gt;</span>  keys[<span class="dv">1</span>][<span class="dv">1</span>](x)<span class="op">,</span> domains[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">,</span> domains[<span class="dv">1</span>][<span class="dv">1</span>])<span class="op">,</span> {<span class="dt">stroke</span><span class="op">:</span> <span class="st">'red'</span>})<span class="op">,</span></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">line</span>(<span class="fu">sample</span>((x) <span class="kw">=&gt;</span> keys[<span class="dv">2</span>][<span class="dv">1</span>](x)<span class="op">,</span> domains[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">,</span> domains[<span class="dv">1</span>][<span class="dv">1</span>])<span class="op">,</span> {<span class="dt">stroke</span><span class="op">:</span> <span class="st">'blue'</span>})]</span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> Plot<span class="op">.</span><span class="fu">plot</span>({</span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a>    <span class="dt">y</span><span class="op">:</span> {<span class="dt">domain</span><span class="op">:</span> domains[<span class="dv">0</span>]}<span class="op">,</span></span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a>    <span class="dt">title</span><span class="op">:</span> <span class="st">"Loss: "</span> <span class="op">+</span> loss<span class="op">.</span><span class="fu">toFixed</span>(<span class="dv">3</span>)<span class="op">,</span></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>    <span class="dt">color</span><span class="op">:</span> {<span class="dt">type</span><span class="op">:</span> <span class="st">"linear"</span><span class="op">,</span> <span class="dt">legend</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"Loss"</span><span class="op">,</span> <span class="dt">scheme</span><span class="op">:</span> <span class="st">"BuRd"</span><span class="op">,</span> <span class="dt">domain</span><span class="op">:</span> [<span class="dv">0</span><span class="op">,</span> <span class="dv">100</span>]}<span class="op">,</span></span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a>    <span class="dt">marks</span><span class="op">:</span> [</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">line</span>(<span class="fu">sample</span>((x) <span class="kw">=&gt;</span> <span class="fu">predict</span>([x]<span class="op">,</span> weights<span class="op">,</span> index_accessors)<span class="op">,</span> domains[<span class="dv">1</span>][<span class="dv">0</span>]<span class="op">,</span> domains[<span class="dv">1</span>][<span class="dv">1</span>])<span class="op">,</span> {<span class="dt">stroke</span><span class="op">:</span> <span class="st">'black'</span>})<span class="op">,</span></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a>      Plot<span class="op">.</span><span class="fu">dot</span>(data<span class="op">,</span> {<span class="dt">x</span><span class="op">:</span> accessors[<span class="dv">0</span>]<span class="op">,</span> <span class="dt">y</span><span class="op">:</span> get_label<span class="op">,</span> <span class="dt">stroke</span><span class="op">:</span> stroke_shade })</span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a>    ]<span class="op">.</span><span class="fu">concat</span>(a)</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-3" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-5" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-6" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-7" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-8" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-9" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-10" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-11" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-12" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-13" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-14" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-15" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-16" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-17" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-18" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-19" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-20" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-21" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-22" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-23" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-24" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-25" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<section id="neural-networks" class="level1">
<h1>Neural networks</h1>
<section id="neural-networks-with-matrices" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks-with-matrices">Neural networks with matrices</h2>
<p>Let’s return to our simple neural network example, where we have 2 inputs and 3 neurons (transforms): <span class="math display">\[\mathbf{x} = \begin{bmatrix} x_1\\ x_2 \end{bmatrix}, \quad \mathbf{w}_0 = \begin{bmatrix} w_{01} \\ w_{02} \end{bmatrix}\]</span> <span class="math display">\[
f(\mathbf{x})=\phi(\mathbf{x})^T \mathbf{w}_0,\quad \phi(\mathbf{x}) = \begin{bmatrix}  \sigma(\mathbf{x}^T \mathbf{w}_1) \\ \sigma(\mathbf{x}^T \mathbf{w}_2) \\ \sigma(\mathbf{x}^T \mathbf{w}_3) \end{bmatrix} =
\begin{bmatrix}  \sigma(x_1 w_{11} + x_2 w_{12}) \\ \sigma(x_1 w_{21} + x_2 w_{22}) \\ \sigma(x_1 w_{31} + x_2 w_{32}) \end{bmatrix}
\]</span></p>
<p>Again, we can represent this pictorially again as a node-link diagram:</p>
<div class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Let’s look at a more compact way to write this, using a weight <em>matrix</em> for the neural network layer. Let’s look at the transform before we apply the sigmoid function:</p>
<p><span class="math display">\[
\begin{bmatrix}  \mathbf{x}^T \mathbf{w}_1 \\ \mathbf{x}^T \mathbf{w}_2 \\ \mathbf{x}^T \mathbf{w}_3 \end{bmatrix} =
\begin{bmatrix}  x_1 w_{11} + x_2 w_{12} \\ x_1 w_{21} + x_2 w_{22} \\ x_1 w_{31} + x_2 w_{32} \end{bmatrix} = \begin{bmatrix} w_{11} &amp; w_{12} \\w_{21} &amp; w_{22} \\ w_{31} &amp; w_{32} \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}
\]</span></p>
<p>If we define a matrix <span class="math inline">\(\mathbf{W}\)</span> for all of the weights as:</p>
<p><span class="math display">\[
\mathbf{W} = \begin{bmatrix} w_{11} &amp; w_{12} \\w_{21} &amp; w_{22} \\ w_{31} &amp; w_{32} \end{bmatrix}
\]</span></p>
<p>we get:</p>
<p><span class="math display">\[
\begin{bmatrix}  \mathbf{x}^T \mathbf{w}_1 \\ \mathbf{x}^T \mathbf{w}_2 \\ \mathbf{x}^T \mathbf{w}_3 \end{bmatrix} = \mathbf{W}\mathbf{x} = (\mathbf{x}^T\mathbf{W}^T)^T
\]</span><br>
If we let <span class="math inline">\(h\)</span> be the number of neuron (or hidden layer units) then this is a <span class="math inline">\(h \times d\)</span> matrix. Therefore, we can write our transform as:</p>
<p><span class="math display">\[
\phi(\mathbf{x}) = \sigma(\mathbf{x}^T\mathbf{W}^T)^T, \quad f(\mathbf{x}) = \sigma(\mathbf{x}^T\mathbf{W}^T) \mathbf{w}_0
\]</span></p>
<p>Recall that if we have multiple observations, as in a dataset, we define them together as an <span class="math inline">\(N \times d\)</span> matrix <span class="math inline">\(\mathbf{X}\)</span> such that each <em>row</em> is an observation:</p>
<p><span class="math display">\[
\mathbf{X} = \begin{bmatrix} \mathbf{x}_1^T \\ \mathbf{x}_2^T \\ \mathbf{x}_3^T  \\ \vdots  \end{bmatrix}
\]</span></p>
<p>Therefore, we can transform all of these observations at once by multiplying this matrix by <span class="math inline">\(\mathbf{W}^T\)</span>.</p>
<p><span class="math display">\[
\phi(\mathbf{X}) = \sigma(\mathbf{X}\mathbf{W}^T)^T = \begin{bmatrix} \sigma(\mathbf{x}_1^T\mathbf{w}_1) &amp; \sigma(\mathbf{x}_1^T\mathbf{w}_2) &amp; \dots  &amp; \sigma(\mathbf{x}_1^T\mathbf{w}_h \\
\sigma(\mathbf{x}_2^T\mathbf{w}_1) &amp; \sigma(\mathbf{x}_2^T\mathbf{w}_2) &amp; \dots  &amp; \sigma(\mathbf{x}_2^T\mathbf{w}_h) \\
\vdots &amp; \vdots &amp; \ddots  &amp; \vdots \\
\sigma(\mathbf{x}_N^T\mathbf{w}_1) &amp; \sigma(\mathbf{x}_N^T\mathbf{w}_2) &amp; \dots  &amp; \sigma(\mathbf{x}_N^T\mathbf{w}_h)
\end{bmatrix}
\]</span></p>
<p>We see that this is an <span class="math inline">\(N \times h\)</span> matrix where each row is a transformed observation! We can then write our full prediction function as</p>
<p><span class="math display">\[
\quad f(\mathbf{x}) = \sigma(\mathbf{X}\mathbf{W}^T) \mathbf{w}_0
\]</span></p>
<p>To summarize:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{X}: \quad N \times d\)</span> matrix of observations</p></li>
<li><p><span class="math inline">\(\mathbf{W}: \quad h \times d\)</span> matrix of network weights</p></li>
<li><p><span class="math inline">\(\mathbf{w}_0: \quad h\ (\times 1)\)</span> vector of linear regression weights</p></li>
</ul>
<p>If we check that our dimensions work for matrix multiplication we see that we get the <span class="math inline">\(N\times 1\)</span> vector of predictions we are looking for!</p>
<p><span class="math display">\[
(N \times d) (h \times d)^T (h \times 1) \rightarrow (N \times d) (d \times h) (h \times 1) \rightarrow (N \times h) (h \times 1)
\]</span></p>
<p><span class="math display">\[
\longrightarrow (N \times1)
\]</span></p>
</section>
<section id="benefits-of-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="benefits-of-neural-networks">Benefits of neural networks</h2>
<p>We’ve seen that the neural network transform is still fairly restrictive, with a limited number of neurons we can’t fit any arbitrary function. In fact, if we choose our feature transforms wisely we can do better than than a neural network.</p>
<p>For example, consider the simple 3-neuron network above. We can see that if we try to fit a circular dataset with it, it performs worse than an explicit transform with <span class="math inline">\(x_1^2\)</span> and <span class="math inline">\(x_2^2\)</span>.</p>
<ul>
<li><p><a href="https://playground.tensorflow.org/#activation=sigmoid&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=3&amp;seed=0.46216&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;batchSize_hide=true&amp;dataset_hide=true&amp;regularization_hide=true&amp;resetButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">Circle dataset with neural network</a></p></li>
<li><p><a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=&amp;seed=0.10871&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=true&amp;ySquared=true&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;percTrainData_hide=true&amp;regularizationRate_hide=true&amp;numHiddenLayers_hide=true">Circle dataset with</a> <span class="math inline">\(x_1^2\)</span> and <span class="math inline">\(x_2^2\)</span>:</p></li>
</ul>
<p>Similarly, for a cross dataset, we can do better with the feature transform that includes <span class="math inline">\(x_1x_2\)</span> as a feature:</p>
<ul>
<li><p><a href="https://playground.tensorflow.org/#activation=sigmoid&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=3&amp;seed=0.46216&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;batchSize_hide=true&amp;dataset_hide=true&amp;regularization_hide=true&amp;resetButton_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">Cross dataset with neural network</a></p></li>
<li><p><a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=&amp;seed=0.26985&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=true&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">Cross dataset with</a> <span class="math inline">\(x_1x_2\)</span></p></li>
</ul>
<p>However, if we choose the <em>wrong</em> feature transform for a given dataset, we do far worse.</p>
<ul>
<li><p><a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=&amp;seed=0.10871&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=true&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;percTrainData_hide=true&amp;regularizationRate_hide=true&amp;numHiddenLayers_hide=true">Circle dataset with</a> <span class="math inline">\(x_1 x_2\)</span></p></li>
<li><p><a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=&amp;seed=0.06128&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=true&amp;ySquared=true&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;showTestData_hide=true&amp;stepButton_hide=true&amp;activation_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;resetButton_hide=true&amp;regularization_hide=true&amp;dataset_hide=true&amp;batchSize_hide=true&amp;learningRate_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;numHiddenLayers_hide=true">Cross dataset with</a> <span class="math inline">\(x_1^2\)</span> and <span class="math inline">\(x_2^2\)</span></p></li>
</ul>
<p>We see that the real power of the neural network here is the ability to adapt the transform to the given dataset, without needing to carefully choose the correct transform!</p>
</section>
<section id="deep-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="deep-neural-networks">Deep Neural Networks</h2>
<p>What we’ve seen so far is a neural network with a <em>single</em> hidden layer, meaning that we create a feature transform for our data and then simply use that to make our prediction. We see that each individual feature transform is a bit limited, being just a logistic regression function.</p>
<p><span class="math display">\[\phi(\mathbf{x})_i = \sigma(\mathbf{x}^T \mathbf{w}_i)\]</span><br>
No matter what we set <span class="math inline">\(\mathbf{w}_i\)</span> this transform would not be able to replicate a transform like <span class="math inline">\(\phi(\mathbf{x})_i = x_i^2\)</span>. However, we’ve already seen a way to make logistic regression more expressive: <strong>neural networks</strong>!</p>
<p>The idea behind a <em>deep</em> or <em>multi-layer</em> neural network is that we can apply this idea of neural network feature transforms recursively:</p>
<p><span class="math display">\[\phi(\mathbf{x})_i = \sigma(\sigma(\mathbf{x}^T\mathbf{W}^T) \mathbf{w}_i)\]</span></p>
<p>Here we’ve transformed our input before computing our feature transform. In terms of a dataset we can write the full prediction function for this <em>2-layer</em> network as:</p>
<p><span class="math display">\[
f(\mathbf{X}) = \sigma(\sigma(\mathbf{X}\mathbf{W}_1^T)\mathbf{W}_2^T)\mathbf{w}_0
\]</span></p>
<p>We’ve now defined a set of weight parameters for each of our 2 <em>hidden layers</em> <span class="math inline">\(\mathbf{W}_1\)</span> and <span class="math inline">\(\mathbf{W}_2\)</span>. It’s a little easier to see what’s happening here if we look a our diagram for this case:</p>
<div class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We can see that stacking these transforms allows us to fit even more complicated functions <a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=spiral&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,4,4,4&amp;seed=0.88060&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">here</a>. Note that we are still not limited to doing this twice! We can fit many layers of transforms:</p>
<p><img src="nn(5).svg" class="img-fluid"></p>
<p>Later on in the semester we’ll talk in more depth about the effect of the number of layers and the number of neurons per layer!</p>
</section>
<section id="optimizing-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="optimizing-neural-networks">Optimizing neural networks</h2>
<p>We can still define a <strong>loss function</strong> for a neural network in the same way we did with our simpler linear models. The only difference is that now we have more parameters to choose:</p>
<p><span class="math display">\[
\mathbf{Loss}(\mathbf{w}_0,\mathbf{W}_1,...)
\]</span></p>
<p>Let’s look at the logistic regression negative log-likelihood loss for the simple neural network we saw above (for simplicity we’ll just call the network weights <span class="math inline">\(\mathbf{W}\)</span>). The probability of class 1 is estimated as:</p>
<p><span class="math display">\[
p(y=1\mid \mathbf{x}, \mathbf{w}_0,\mathbf{W})=\sigma(\phi(\mathbf{x})^T \mathbf{w}_0) = \sigma(\sigma(\mathbf{x}^T \mathbf{W}^T) \mathbf{w}_0),\quad \phi(\mathbf{x}) = \begin{bmatrix}  \sigma(\mathbf{x}^T \mathbf{W}_{1}) \\ \sigma(\mathbf{x}^T \mathbf{W}_{2}) \\ \sigma(\mathbf{x}^T \mathbf{W}_{3}) \end{bmatrix}
\]</span> <span class="math display">\[ = \sigma\big(w_{01} \cdot\sigma(x_1 W_{11} + x_2 W_{12}) + w_{02} \cdot\sigma(x_1 W_{21} + x_2 W_{22})+ w_{03} \cdot\sigma(x_1 W_{31} + x_2 W_{32}) \big)\]</span></p>
<p>Therefore the negative log-likelihood is:</p>
<p><span class="math display">\[
\mathbf{NLL}(\mathbf{w}_0,\mathbf{W}, \mathbf{X}, \mathbf{y}) = -\sum_{i=1}^N \bigg[ y_i\log p(y=1\mid \mathbf{x}, \mathbf{w}_0,\mathbf{W}) + (1-y_i)\log p(y=0\mid \mathbf{x}, \mathbf{w}_0,\mathbf{W}) \bigg]
\]</span></p>
<p><span class="math display">\[
= -\sum_{i=1}^N \log \sigma\big((2y_i-1) \phi(\mathbf{x}_i)^T \mathbf{w}\big)
\]</span></p>
<p>We see that we can write out a full expression for this loss in term of all the inputs and weights. We can even define the gradient of this loss with respect to all the weights:</p>
<p><span class="math display">\[
\nabla_{\mathbf{w}_0} \mathbf{NLL}(\mathbf{w}_0,\mathbf{W}, \mathbf{X}, \mathbf{y}) = \begin{bmatrix} \frac{\partial \mathbf{NLL}}{\partial w_{01}} \\ \frac{\partial \mathbf{NLL}}{\partial w_{02}} \\ \frac{\partial \mathbf{NLL}}{\partial w_{03}} \\ \vdots\end{bmatrix}, \quad \nabla_{\mathbf{W}}\mathbf{NLL}(\mathbf{w}_0,\mathbf{W}, \mathbf{X}, \mathbf{y}) =
\begin{bmatrix} \frac{\partial \mathbf{NLL}}{\partial W_{11}} &amp;  \frac{\partial \mathbf{NLL}}{\partial W_{12}} &amp; \dots &amp; \frac{\partial \mathbf{NLL}}{\partial W_{1d}}  \\
\frac{\partial \mathbf{NLL}}{\partial W_{21}} &amp;  \frac{\partial \mathbf{NLL}}{\partial W_{22}} &amp; \dots &amp; \frac{\partial \mathbf{NLL}}{\partial W_{2d}} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial \mathbf{NLL}}{\partial W_{h1}} &amp;  \frac{\partial \mathbf{NLL}}{\partial W_{h2}} &amp; \dots &amp; \frac{\partial \mathbf{NLL}}{\partial W_{hd}}
\end{bmatrix}
\]</span></p>
<p>Note that as <span class="math inline">\(\mathbf{W}\)</span> is a matrix, the gradient with respect to <span class="math inline">\(\mathbf{W}\)</span> is also a matrix! Our gradient descent algorithm can proceed in the same way it did for our linear models, but here we now need to update both sets of parameters:</p>
<p><span class="math display">\[
\mathbf{w}_0^{(k+1)} \longleftarrow \mathbf{w}_0^{(k)} -\alpha \nabla_{\mathbf{w}_0} \mathbf{NLL}(\mathbf{w}_0,\mathbf{W}, \mathbf{X}, \mathbf{y}), \quad \mathbf{W}^{(k+1)} \longleftarrow \mathbf{W}^{(k)} -\alpha \nabla_{\mathbf{W}} \mathbf{NLL}(\mathbf{w}_0,\mathbf{W}, \mathbf{X}, \mathbf{y})
\]</span></p>
<p>The important question now becomes: <em>how do we compute these gradients?</em></p>
</section>
</section>
<section id="automatic-differentiation" class="level1">
<h1>Automatic Differentiation</h1>
<p>In this section we’ll derive <em>algorithms</em> for computing the derivative of <em>any</em> function.</p>
<section id="motivation" class="level2">
<h2 class="anchored" data-anchor-id="motivation">Motivation</h2>
<p>We saw above that the NLL for logistic regression with a neural network is:</p>
<p><span class="math display">\[
\mathbf{NLL}(\mathbf{w}_0,\mathbf{W}, \mathbf{X}, \mathbf{y}) = -\sum_{i=1}^N \log \sigma\big((2y_i-1) \phi(\mathbf{x}_i)^T \mathbf{w}\big)
\]</span></p>
<p>If we write this out in terms of the individual values we get:</p>
<p><span class="math display">\[
= -\sum_{i=1}^N \log \sigma\big((2y_i-1)\sigma\big(w_{01} \cdot\sigma(x_1 W_{11} + x_2 W_{12}) + w_{02} \cdot\sigma(x_1 W_{21} + x_2 W_{22})+ w_{03} \cdot\sigma(x_1 W_{31} + x_2 W_{32}) \big)\big)
\]</span></p>
<p>We could use the same approach as usual to find the derivative of this loss with respect to each individual weight parameter, but it would be very tedious and this is only a <em>single-layer network</em>! Things would only get more complicated with more layers. Furthermore if we changed some aspect of the network, like the activation function, we’d have to do it all over again.</p>
<p>Ideally we’d like a programmatic way to compute derivatives. Knowing that we compute derivatives using a fixed set of known rules, this should be possible!</p>
</section>
<section id="the-chain-rule-revisited" class="level2">
<h2 class="anchored" data-anchor-id="the-chain-rule-revisited">The chain rule revisited</h2>
<p>While we often think about the chain rule in terms of functions:</p>
<p><span class="math display">\[
\frac{d}{dx}f(g(x)) = f'(g(x))g'(x)
\]</span></p>
<p>It’s often easier to view it imperatively, in terms of individual values. For example we might say:</p>
<p><span class="math display">\[
b = g(x)
\]</span></p>
<p><span class="math display">\[
a = f(b)
\]</span></p>
<p>In this case we can write the chain rule as:</p>
<p><span class="math display">\[
\frac{da}{dx} = \frac{da}{db}\frac{db}{dx}
\]</span></p>
<p>This corresponds with how we might think about this in code. For example we might have the code:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> log(b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In this case we have:</p>
<p><span class="math display">\[
a = \log(b), \quad b = x^2
\]</span></p>
<p>We can compute the derivative of <span class="math inline">\(a\)</span> with respect to <span class="math inline">\(x\)</span> using the chain rule as:</p>
<p><span class="math display">\[
\frac{da}{db} = \frac{1}{b}, \quad \frac{db}{dx} = 2x
\]</span></p>
<p><span class="math display">\[
\frac{da}{dx} = \bigg(\frac{1}{b}\bigg)(2x) = \frac{2x}{x^2} = \frac{2}{x}
\]</span></p>
</section>
<section id="composing-many-operations" class="level2">
<h2 class="anchored" data-anchor-id="composing-many-operations">Composing many operations</h2>
<p>For more complex functions, we might be composing many more operations, but we can break down derivative computations in the same way. For example, if we want the derivative with respect to <span class="math inline">\(x\)</span> of some simple loss:</p>
<p><span class="math display">\[
L=-\log \sigma\big(w x^2\big)
\]</span></p>
<p>We can break this down into each individual operation that we apply:</p>
<p><span class="math display">\[
a = x^2
\]</span></p>
<p><span class="math display">\[
b=wa
\]</span></p>
<p><span class="math display">\[
c=\sigma(b)
\]</span></p>
<p><span class="math display">\[
g= \log c
\]</span></p>
<p><span class="math display">\[
L=-g
\]</span><br>
The chain rule tells us that:</p>
<p><span class="math display">\[
\frac{dL}{dx} = \frac{dL}{dg}\frac{dg}{dc}\frac{dc}{db}\frac{db}{da}\frac{da}{dx}
\]</span><br>
Since each step is a single operation with a known derivative, we can easily compute every term above! Thus, we begin to see a recipe for computing derivatives programatically. Every time we perform some operation, we will also compute the derivative with respect to the input (we can’t just compute the derivatives because each derivative needs the preceding value, e.g.&nbsp;<span class="math inline">\(\frac{dg}{dc}=\frac{1}{c}\)</span>, so we need to first compute <span class="math inline">\(c\)</span>).</p>
<p>We can visually look at the chain of computation that we’re performing as a diagram that shows each step and the result.</p>
<div class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We call this structure the <strong>computational graph</strong>.</p>
</section>
<section id="forward-and-reverse-mode-automatic-differentiation" class="level2">
<h2 class="anchored" data-anchor-id="forward-and-reverse-mode-automatic-differentiation">Forward and reverse mode automatic differentiation</h2>
<p>We are not actually interested in all of the intermediate derivatives ( <span class="math inline">\(\frac{db}{da}, \frac{dc}{db}\)</span> etc.), so it doesn’t make much sense to compute all of them and then multiply them together. Instead, we’d rather just incrementally compute the value we’re interested in <span class="math inline">\(\frac{dL}{dx}\)</span>, as we go.</p>
<p>There are 2 ways we could consider doing this. One way is to always keep track of the derivative of the current value with respect to <span class="math inline">\(x\)</span>. So in the diagram above, each time we perform a new operation we will also compute the derivative of the operation and then update our knowledge of the derivative with respect to <span class="math inline">\(x\)</span>. For example for the operation going from <span class="math inline">\(b\)</span> to <span class="math inline">\(c\)</span>:</p>
<p><span class="math display">\[
c \leftarrow \sigma(b), \quad \frac{dc}{dx} \leftarrow \frac{dc}{db}\cdot\frac{db}{dx}
\]</span></p>
<p>We call this approach <strong>forward-mode automatic differentiation</strong>.</p>
<p>The alternative approach is to work backwards, first compute <span class="math inline">\(L\)</span> and <span class="math inline">\(\frac{dL}{dg}\)</span> and then go backwards through the chain updating the derivative of the final output with respect to each input for the <span class="math inline">\(b\)</span> to <span class="math inline">\(c\)</span> operation this looks like:</p>
<p><span class="math display">\[
c \leftarrow \sigma(b), \quad \frac{dL}{db} \leftarrow \frac{dc}{db}\cdot\frac{dL}{dc}
\]</span></p>
<p>This means we need to do our computation in 2 passes. First we need to go through the chain of operations to compute <span class="math inline">\(L\)</span>, then we need to go backwards through the chain to compute <span class="math inline">\(\frac{dL}{dx}\)</span>. Note that computing each intermediate derivative requires the a corresponding intermediate value (e.g.&nbsp;<span class="math inline">\(\frac{dc}{db}\)</span> requires <span class="math inline">\(b\)</span> to compute). So we need to store all the intermediate values as we go. The approach is called <strong>reverse-mode automatic differentiation</strong> or more commonly: <strong>backpropagation</strong>. We can summarize both approaches below:</p>
<div class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="automatic-differentiation-with-multiple-inputs" class="level2">
<h2 class="anchored" data-anchor-id="automatic-differentiation-with-multiple-inputs">Automatic differentiation with multiple inputs</h2>
<p>You might wonder why we’d ever use reverse-mode when it seems to require much more complication in keeping track of all the intermediate values. To see why it is useful, lets’s consider the common case where we would like to take derivatives with respect to multiple inputs at the same time. For example we might have an expression like:</p>
<p><span class="math display">\[
-\log \sigma (w_1 x_1+w_2x_2 +w_3x_3)
\]</span></p>
<p>In this case we want to find the gradient:</p>
<p><span class="math display">\[
\frac{dL}{d\mathbf{x}} = \begin{bmatrix}\frac{dL}{dx_1} \\ \frac{dL}{dx_2} \\ \frac{dL}{dx_3} \end{bmatrix}
\]</span></p>
<p>We see that in forward mode, we now need to keep a vector of gradients at many steps if we want to compute the derivative with respect to every input!</p>
<div class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In reverse mode, however we only ever need to keep the derivative of the <em>loss</em> with respect to the current value. If we assume that the loss is always a single value, this is much more efficient!</p>
<div class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="reusing-values" class="level2">
<h2 class="anchored" data-anchor-id="reusing-values">Reusing values</h2>
<p>One thing we need to consider is the fact that values can be used in multiple different operations. For example, consider the code below.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> loss(x):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> <span class="dv">5</span> <span class="op">*</span> a</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    c <span class="op">=</span> log(a)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    g <span class="op">=</span> b <span class="op">*</span> c</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> <span class="op">-</span>g</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> L</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This corresponds to the following sequence of operations:</p>
<p><span class="math display">\[
a = x^2
\]</span></p>
<p><span class="math display">\[
b=5a
\]</span></p>
<p><span class="math display">\[
c=\log a
\]</span></p>
<p><span class="math display">\[
g = bc
\]</span></p>
<p><span class="math display">\[
L=-b
\]</span></p>
<p>We see that both <span class="math inline">\(b\)</span> <em>and</em> <span class="math inline">\(c\)</span> depend on <span class="math inline">\(a\)</span>. Leading to the following computational graph:</p>
<div class="cell" data-execution_count="11">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In forward mode this means that we compute 2 different values for <span class="math inline">\(\frac{dg}{dx}\)</span>, one from <span class="math inline">\(b\)</span> <span class="math inline">\((\frac{dg}{db}\cdot\frac{db}{dx})\)</span> and one from <span class="math inline">\(c\)</span> <span class="math inline">\((\frac{dg}{dc}\cdot\frac{dc}{dx})\)</span>.</p>
<div class="cell" data-execution_count="12">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In reverse mode this means that we compute 2 different values for <span class="math inline">\(\frac{dL}{da}\)</span>, one from <span class="math inline">\(b\)</span> <span class="math inline">\((\frac{dL}{db}\cdot\frac{db}{da})\)</span> and one from <span class="math inline">\(c\)</span> <span class="math inline">\((\frac{dL}{dc}\cdot\frac{dc}{da})\)</span>.</p>
<div class="cell" data-execution_count="13">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The resolution in both cases is simple! Just add the two terms. So in forward mode:</p>
<p><span class="math display">\[\frac{dg}{dx} = \frac{dg}{db}\cdot \frac{db}{dx} +\frac{dg}{dc}\cdot \frac{dc}{dx}\]</span></p>
<p>In reverse mode:</p>
<p><span class="math display">\[\frac{dL}{da} = \frac{dL}{db}\cdot \frac{db}{da} + \frac{dL}{dc}\cdot \frac{dc}{da} \]</span></p>
<p>The forward case for this example is just an application of the product rule:</p>
<p><span class="math display">\[
g =bc
\]</span></p>
<p><span class="math display">\[
\frac{dg}{dx} =\frac{dg}{db}\cdot \frac{db}{dx} +\frac{dg}{dc}\cdot \frac{dc}{dx} = c\cdot \frac{db}{dx} +b \cdot \frac{dc}{dx}
\]</span></p>
<p>For reverse mode we need to expand an rearrange a bit:</p>
<p><span class="math display">\[
\frac{dL}{da} =\frac{dL}{dg}\cdot \frac{dg}{da}
\]</span></p>
<p><span class="math display">\[
\frac{dg}{da} =\frac{dg}{db}\cdot \frac{db}{da} +\frac{dg}{dc}\cdot \frac{dc}{da}
\]</span></p>
<p><span class="math display">\[
\frac{dL}{da} =\frac{dL}{dg}\bigg( \frac{dg}{db}\cdot \frac{db}{da} +\frac{dg}{dc}\cdot \frac{dc}{da} \bigg)
\]</span></p>
<p><span class="math display">\[
=\frac{dL}{dg} \frac{dg}{db} \frac{db}{da} + \frac{dL}{dg}\frac{dg}{dc} \frac{dc}{da}
\]</span></p>
<p><span class="math display">\[
=\frac{dL}{db}\cdot \frac{db}{da} + \frac{dL}{dc}\cdot \frac{dc}{da}
\]</span></p>
<p>This also works for addition:</p>
<p><span class="math display">\[
g =b + c
\]</span></p>
<p><span class="math display">\[
\frac{dg}{dx} =\frac{dg}{db}\cdot \frac{db}{dx} +\frac{dg}{dc}\cdot \frac{dc}{dx}
\]</span></p>
<p><span class="math display">\[
\frac{dg}{db}=1,\ \frac{dg}{dc}=1
\]</span></p>
<p><span class="math display">\[
\frac{dg}{dx} =\frac{db}{dx} + \frac{dc}{dx}
\]</span></p>
<p>And in general any binary operation! (Division, powers etc.).</p>
</section>
<section id="partial-and-total-derivatives" class="level2">
<h2 class="anchored" data-anchor-id="partial-and-total-derivatives">Partial and total derivatives</h2>
<p>So far we’ve been a bit sloppy in our discussion of derivatives. To see why, let’s consider one more case:</p>
<p><span class="math display">\[
a = x^2
\]</span></p>
<p><span class="math display">\[
b=5a
\]</span></p>
<p><span class="math display">\[
c = a b
\]</span></p>
<p><span class="math display">\[
L=-c
\]</span></p>
<div class="cell" data-execution_count="14">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Saying that <span class="math inline">\(\frac{dc}{da}=b\)</span> isn’t quite correct, because <span class="math inline">\(b\)</span> <em>also</em> depends on <span class="math inline">\(a\)</span>, really <span class="math inline">\(\frac{dc}{da} =\frac{dc}{da}+\frac{dc}{db}\frac{db}{da}\)</span>. We already account for this in our automatic differentiation though, so we want a way to talk about the derivative of an operation with respect to it’s inputs <em>ignoring how the inputs may depend on each other</em>.</p>
<p>This is where the notion of a <strong>partial derivative</strong> comes in, the <em>partial</em> <em>derivative</em> of function with respect to an input is the derivative ignoring any dependencies between inputs. We’ve already seen how we denote this:</p>
<p><span class="math display">\[
\frac{\partial c}{\partial a} = b =5a
\]</span></p>
<p>The <strong>total derivative</strong> is the derivative where we do account for this. In our example:</p>
<p><span class="math display">\[
\frac{dc}{da} =\frac{\partial c}{\partial a}+\frac{\partial c}{\partial b}\frac{\partial b}{\partial a} = 5a + 5a = 10a
\]</span><br>
In our earlier examples, we typically had partial derivatives equal to total derivatives, so the distinction wasn’t really important. This example shows why it is.</p>
<p>Let’s see our earlier example, but this time we’ll make the distinction between partial and total derivatives explicit</p>
<div class="cell" data-execution_count="15">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="cell-output cell-output-display">
<p><img src="notes_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This is also why we specify gradients in terms of partial derivatives! If we’re taking the gradient of a function with respect to multiple inputs, we don’t know where these inputs come from. They might depend on each other! By specifying gradients at partial derivatives, we make it clear that we’re not accounting for that.</p>
</section>
<section id="implementing-automatic-differentiation" class="level2">
<h2 class="anchored" data-anchor-id="implementing-automatic-differentiation">Implementing automatic differentiation</h2>
<p>We see that our computational graph is essentially a tree-like data-structure call a <em>directed acyclic graph,</em> essentially a tree where each node can have more than one parent. Therefore we can implement it much like a tree!</p>
<p>In particular we can create a class that represents a node in our computational graph (corresponding to the result of some operation). This class will store the value of that operation as well as it’s parents in the computational graph.</p>


</section>
</section>

</main> <!-- /main -->
<script type="ojs-module-contents">
{"contents":[{"methodName":"interpret","cellName":"ojs-cell-1","inline":false,"source":"Plot = import(\"https://esm.sh/@observablehq/plot\") \nd3 = require(\"d3@7\")\ntopojson = require(\"topojson\")\nMathJax = require(\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.min.js\").catch(() => window.MathJax)\ntf = require(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js\").catch(() => window.tf)\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() => {});\n  await require(\"three@0.130.0/examples/js/loaders/SVGLoader.js\").catch(() => {});\n  return THREE;\n}\n\nfunction sample(f, start, end, nsamples=100) {\n  let arr = [...Array(nsamples).keys()]\n  let dist = end - start\n  function arrmap(ind) {\n    const x = (ind * dist) / nsamples + start;\n    return [x, f(x)];\n  }\n  return arr.map(arrmap)\n}\n\nfunction sigmoid(x){\n  return 1 / (1 + Math.exp(-x));\n}\n\nfunction sum(x) {\n  let s = 0;\n  for (let i = 0; i < x.length; i++ ) {\n    s += x[i];\n  }\n  return s;\n}\n\nfunction mean(x) {\n  let s = 0;\n  for (let i = 0; i < x.length; i++ ) {\n    s += x[i];\n  }\n  return s / x.length;\n}\n\nfunction cross_ent(x, y) {\n  return y ? -Math.log(sigmoid(x)) : -Math.log(sigmoid(-x));\n}\n\nfunction se(x, y) {\n  return (x - y) * (x - y);\n}\n\nfunction shuffle(array) {\n  let currentIndex = array.length,  randomIndex;\n\n  // While there remain elements to shuffle.\n  while (currentIndex > 0) {\n\n    // Pick a remaining element.\n    randomIndex = Math.floor(Math.random() * currentIndex);\n    currentIndex--;\n\n    // And swap it with the current element.\n    [array[currentIndex], array[randomIndex]] = [\n      array[randomIndex], array[currentIndex]];\n  }\n\n  return array;\n}\n\nfunction acc(x, y) {\n  return Number(y == (x  > 0));\n}\n\nfunction grid_func(f, width, height, x1, y1, x2, y2) {\n  let values = new Array(width * height);\n  const xstride = (x2 - x1) / width;\n  const ystride = (y2 - y1) / height;\n\n  \n  let y = 0;\n  let x = 0;\n  let ind = 0;\n  for (let i = 0; i < height; i++ ) {\n    for (let j = 0; j < width; j++, ind++) {\n      x = x1 + j * xstride;\n      y = y1 + i * ystride;\n      values[ind] = f(x, y);\n    }\n  }\n  return {width: width, height: height, x1: x1, y1: y1, x2: x2, y2: y2, values: values};\n}\n\nfunction get_accessors(keys, byindex=false) {\n  let isString = value => typeof value === 'string';\n  \n  let index = 0;\n  let indexmap = {};\n  let accessors = [];\n  for (let i = 0; i < keys.length; i++){\n    let k = keys[i];\n    if (Array.isArray(k)) {\n      let access = isString(k[0]) ? (x => x[k[0]]) : k[0];\n      \n      if (byindex) {\n        if (isString(k[0]) && !(k[0] in indexmap)) {\n          indexmap[k[0]] = index;\n          index++;\n        }\n        let accessindex = indexmap[k[0]];\n        access = x => x[accessindex];\n        let process = k[1];\n        let final_access = x => process(access(x));\n        accessors.push(final_access);\n      }\n      else {\n        let process = k[1];\n        let final_access = x => process(access(x));\n        accessors.push(final_access);\n      }\n      \n    }\n    else {\n      let access = isString(k) ? (x => x[k]) : k;\n      if (byindex) { \n        if (isString(k) && !(k in indexmap)) {\n          indexmap[k] = index;\n          index++;\n        }\n        let accessindex = indexmap[k];\n        access = x => x[accessindex];\n      }\n      accessors.push(access); \n    }\n  }\n  return accessors;\n}\n\nfunction predict(obs, weights, keys=[\"0\", \"1\", \"2\", \"3\"], byindex=false) {\n  let isString = value => typeof value === 'string';\n  let accessors = get_accessors(keys, byindex);\n  \n  let output = weights[0];\n  let wi = 1;\n  for (let i = 0; (i < keys.length) && (wi < weights.length); i++, wi++){\n    output += weights[wi] * accessors[i](obs);\n  }\n  return output;\n}\n\nfunction mean_loss(f, data, weights, keys, label, l2=0) {\n  let reg = 0;\n  if (l2 > 0){\n    for (let i = 1; i < weights.length; i++) {\n      reg += weights[i] * weights[i];\n    }\n  }\n  \n  const isString = value => typeof value === 'string';\n  const get_label = isString(label) ? (x => x[label]) : label;\n  return mean(data.map(x => f(predict(x, weights, keys), get_label(x)))) + l2 * reg;\n}\n\nfunction get_domains(data, accessors, margin=0.1) {\n  let domains = [];\n  for (let i = 0; i < accessors.length; i++){\n    let xdomain = d3.extent(data, accessors[i]);\n    let xdsize = (xdomain[1] - xdomain[0]);\n    let xmin = xdomain[0] - xdsize * margin;\n    let xmax = xdomain[1] + xdsize * margin;\n    domains.push([xmin, xmax]);\n  }\n  return domains;\n}\n\nfunction logisticPlot2d(data, weights, keys, label, interval=0.05) {\n  const accuracy = mean_loss(acc, data, weights, keys, label);\n  \n  let isString = value => typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x => x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Accuracy: \" + accuracy.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [-0.5, 1.5]},\n    marks: [\n      Plot.contour({\n        fill: (x, y) => sigmoid(predict([x, y], weights, index_accessors)),\n        x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1], interval: interval,\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=> (get_label(x) ? 1.35 : -0.35)})\n    ]\n  });\n}\n\nfunction logisticLossPlot2d(data, weights, keys, label) {\n  const loss = mean_loss(cross_ent, data, weights, keys, label);\n  \n  let isString = value => typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x => x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [0, 5]},\n    marks: [\n      Plot.contour({\n        value: (x, y) => predict([x, y], weights, index_accessors),\n        fillOpacity: 0.2,\n        stroke: \"black\", x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1],\n        thresholds: [-1e6,  0, 0.00001]\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=> cross_ent(predict(x, weights, keys), get_label(x)), \n                      strokeOpacity: 0.5 })\n    ]\n  });\n}\n\nfunction lossPlot2d(f, data, keys, label, l2=0, res=100, x1=-40, y1=-0.015, x2=40,  y2=0.015, vmax=50, nlines=25, ctype=\"sqrt\", scale=(x => x)) {\n  let grid = 0;\n  function lossFunc(w, b) {\n    return scale(mean_loss(f, data, [w, b], keys, label, l2));\n  }\n\n  grid = grid_func(lossFunc,\n                 res, res, x1, y1, x2, y2\n                );\n\n  function plot2d(weights) {\n    let w = weights;\n    if (!(Array.isArray(w[0]))){\n      w = [w];\n    }\n\n    var arrows = w.slice(0, w.length - 1).map(function(e, i) {\n      return e.concat(w[i+1]);\n    });\n\n    let interval= vmax / nlines; \n    let thresholds = [];\n    for (let i = 0; i < nlines; i++) {\n      thresholds.push(i * interval);\n    }\n    let loss = mean_loss(f, data, w[w.length - 1], keys, label, l2)\n    return Plot.plot({\n      title: \"Loss: \" + loss.toFixed(3),\n      color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, vmax], type: ctype},\n      marks: [\n        Plot.contour(grid.values, {width: grid.width, height: grid.height, x1: grid.x1, x2:grid.x2, y1: grid.y1, y2: grid.y2,\n          stroke: Plot.identity, thresholds: thresholds}),\n        Plot.dot(w),\n        Plot.arrow(arrows, {x1: \"0\", y1: \"1\", x2: \"2\", y2: \"3\", stroke: \"black\"})\n      ]\n    })\n  }\n  return plot2d;\n}\n\n\n\nfunction regressionPlot(data, weights, keys, label, l2, f=se, stroke=\"\") {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value => typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x => x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x => f(predict(x, weights, keys), get_label(x)))\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) => predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ]\n  })\n}\n\nfunction errorPlot(data, weights, keys, label, f, options={}) {\n  const isString = value => typeof value === 'string';\n  const get_label = isString(label) ? (x => x[label]) : label;\n  let errors = data.map(x => [predict(x, weights, keys) - get_label(x), f(predict(x, weights, keys), get_label(x))]);\n\n  \n  let sigma = (options['sigma'] || 1);\n  let plots = [];\n  const xdomain = (options['xdomain'] || [-30, 30]);\n  const ydomain = (options['ydomain'] || [0, 0.1]);\n  \n\n  if (options['plotnormal']){\n    let pdf = x => Math.exp(-0.5 * x * x / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'crimson'});    \n    plots.push(normal);\n  }\n  if (options['plotlaplace']){\n    let pdf = x => Math.exp(-0.5 * Math.abs(x) / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'green'});    \n    plots.push(normal);\n  }\n  \n  return Plot.plot({\n    y: {grid: true, domain: ydomain},\n    x: {domain: xdomain},\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      //Plot.rectY(errors, Plot.binX({y: \"count\", fill: x => mean(x.map(v => v[1]))}, {x: \"0\"})),\n      \n      Plot.rectY(errors, Plot.binX({y: \"proportion\"}, {x: \"0\", fill: 'steelblue', interval: 1})),\n      Plot.ruleY([0])\n    ].concat(plots)\n  })\n}\n\nfunction nnPlot(data, weights, keys, label, l2, f=se, stroke=\"\", options=[]) {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value => typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x => x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x => f(predict(x, weights, keys), get_label(x)))\n  }\n\n  let a = []\n  if (options.indexOf(\"Show feature transforms\") >= 0){\n    a = [Plot.line(sample((x) =>  keys[1][1](x), domains[1][0], domains[1][1]), {stroke: 'red'}),\n      Plot.line(sample((x) => keys[2][1](x), domains[1][0], domains[1][1]), {stroke: 'blue'})]\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) => predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ].concat(a)\n  })\n}\n"}]}
</script>
<script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../../lecture6-backpropagation";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "..";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>